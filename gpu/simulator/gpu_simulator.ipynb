{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba3ea87",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## NVidia GPU Simulator\n",
    "\n",
    "Burton Rosenberg\n",
    "30 May 2023\n",
    "\n",
    "-----\n",
    "\n",
    "This code simulates an Nvidia GPU. The class keeps dictionaries for memory objects (ndarrays) and kernels (functions), that are setup before a launch message is sent.\n",
    "\n",
    "The launch is serial, of course, but on the GPU it is parallel. The kernels are run in order to test out the logic of the kernels. Success on the simulator should mean success of the actual device.\n",
    "\n",
    "A difficulty is I wanted the kernels to be defined similar to the nvcc global functions. This means they make reference to variables that are lexicographically out of scope. In nvcc this is taken care of by device references on the host which are attached to actual reference on the device. Here I use a dictionary to map the name of the ndarry or the kernel to the array or kernel, with a bit of preamble for each kernel making the dictionary lookup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3ab455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GPU:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mem = {}\n",
    "        self.ker = {}\n",
    "        \n",
    "    def addKernel(self,name,kernel):\n",
    "        self.ker[name] = kernel\n",
    "\n",
    "    def addMemory(self,name,ndarray):\n",
    "        self.mem[name] = ndarray\n",
    "\n",
    "    def launch(self,name,n_threads,args):       \n",
    "        for i in range(n_threads):\n",
    "            ctx = (self.mem,self.ker,i)\n",
    "            self.ker[name](ctx,args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae9a6b",
   "metadata": {},
   "source": [
    "### The dot product\n",
    "\n",
    "The dot product of two vectors is done in parallel with two kernels,\n",
    "\n",
    "- A straight forward component-wise multiplication\n",
    "- A sum of all elements using a log n depth tree\n",
    "\n",
    "Arranging the sum, this method uses a folding approach. Intuitively this method divides the array in half, and moves the top half over the bottom half, aligning the elements. The sum then updates the values in the lower half.\n",
    "\n",
    "The loop invariant is somthing the answer S is always the sum of the first i elements in the array. Start i at the length of the array and half it every interation, until i is one.\n",
    "\n",
    "<pre>\n",
    "\n",
    "initial array:\n",
    "\n",
    "   +---+---+---+---+---+---+---+---+\n",
    "   | 0   1   2   3   4   5   6   7 |\n",
    "   +---+---+---+---+---+---+---+---+\n",
    "\n",
    "fold in half and add\n",
    "\n",
    "   +---+---+---+---+\n",
    "   | 4   5   6   7 |\n",
    "   +---+---+---+---+\n",
    "   +---+---+---+---+\n",
    "+  | 0   1   2   3 |\n",
    "   +---+---+---+---+\n",
    "====================\n",
    "   +---+---+---+---+\n",
    "   | 4   6   8  10 |\n",
    "   +---+---+---+---+\n",
    "\n",
    "fold in half and add\n",
    "\n",
    "   +---+---+\n",
    "   | 8  10 |\n",
    "   +---+---+\n",
    "   +---+---+\n",
    "+  | 4   6 |\n",
    "   +---+---+\n",
    "====================\n",
    "   +---+---+\n",
    "   |12  16 |\n",
    "   +---+---+\n",
    "   \n",
    "one last time\n",
    "\n",
    "   +---+\n",
    "   |12 |\n",
    "   +---+\n",
    "   +---+\n",
    "+  |16 |\n",
    "   +---+\n",
    "====================\n",
    "   +---+\n",
    "   |28 |\n",
    "   +---+\n",
    "\n",
    "</pre>\n",
    "\n",
    "#### Warp considerations\n",
    "\n",
    "If we use the initial cells of the array, thread lauches are for consecutive thread ID's. We use all the threads in a warp (until we are under array size of 32).\n",
    "\n",
    "#### Memory considerations\n",
    "\n",
    "Each thread has exculsive access to the two memory cells it works with.\n",
    "\n",
    "#### Synchronization\n",
    "\n",
    "Using the default stream, enqueue a sequence of thread launchs according to\n",
    "the having blocksize.\n",
    "\n",
    "#### Efficiency.\n",
    "\n",
    "This has log n phases, each phase using n/2 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f14b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [ 2.  0.  0. 10. 10.  5.  1.  7. 13.  2.  5.  2.  6. 14.  2.  3.]\n",
      "b: [15. 11.  4.  8. 14. 14.  1.  9.  6.  2.  0. 11.  2.  3. 13.  8.]\n",
      "calculated: 592.0, actual: 592.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_dot_product(k):\n",
    "    \n",
    "    def mult_array(ctx,args):\n",
    "        (_m,_k,_tid) = ctx\n",
    "        (a, b) = map((lambda r: _m[r]), args)\n",
    "\n",
    "        a[_tid] *= b[_tid]\n",
    "\n",
    "    def fold_array(ctx,args):\n",
    "        (_m,_k,_tid), (a,k) = ctx, args\n",
    "        a = _m[a]\n",
    "\n",
    "        a[_tid] += a[_tid+k]\n",
    "\n",
    "    n = 2**k\n",
    "\n",
    "    gpu = GPU()\n",
    "    gpu.addKernel('mult_array',mult_array)\n",
    "    gpu.addKernel('fold_array',fold_array)\n",
    "\n",
    "    a = (np.random.randint(0,n,n)).astype(float)\n",
    "    b = (np.random.randint(0,n,n)).astype(float)\n",
    "\n",
    "    gpu.addMemory('a',a)\n",
    "    gpu.addMemory('b',b)\n",
    "    \n",
    "    print(f'a: {a}')\n",
    "    print(f'b: {b}')\n",
    "    d = a.dot(b)\n",
    "\n",
    "    gpu.launch('mult_array',n,('a','b'))\n",
    "    for i in range(k):\n",
    "        gpu.launch('fold_array',n//(2**(i+1)),('a',n//(2**(i+1))))\n",
    "    print(f'calculated: {a[0]}, actual: {d}')\n",
    "\n",
    "\n",
    "test_dot_product(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e672afc",
   "metadata": {},
   "source": [
    "### The partial sum\n",
    "\n",
    "The array is updated so a[i] contains the sum of the original values found in a[j] for all j less than or equal to i.\n",
    "\n",
    "The loop invariant is that blocks of size 2^k, starting of indices mutliples of 2^k, are correctly the partial sum array of just that block. Initially k=0 is satisfied trivially, and finally the k' for which 2^k'==n is the problem solved.\n",
    "\n",
    "The update from k to k+1 takes pairs of consecutive blocks of size 2^k and makes the loop invariant right for the combined block of size. 2^{k+1}. \n",
    "\n",
    "<pre>\n",
    "Initial array:\n",
    "\n",
    "   +---+---+---+---+---+---+---+---+\n",
    "   | 1   2   1   3 | 2   3   2   1 |   L.I. true for 2^0 = 1\n",
    "   +---+---+---+---+---+---+---+---+\n",
    "\n",
    "....\n",
    "\n",
    "   +---+---+---+---+---+---+---+---+\n",
    "   | 1   3   4   7 | 2   5   7   8 |   L.I true for 2^2 =4 \n",
    "   +---+---+---+---+---+---+---+---+\n",
    "                 |   |   |   |   |\n",
    "                 |   V   V   V   V\n",
    "                 +-&gt;   shift up\n",
    "                     |   |   |   |\n",
    "                     V   V   V   V\n",
    "   +---+---+---+---+---+---+---+---+\n",
    "   | 1   3   4   7 | 9  12  14  15 |   L.I true for 2^3 =8\n",
    "   +---+---+---+---+---+---+---+---+               \n",
    "</pre>\n",
    "\n",
    "\n",
    "#### Warp considerations\n",
    "\n",
    "Active threads are in consecutive thread ID's, so the warps are fully untilized \n",
    "except before the block size is 32. The code below launches n threads, but n/2\n",
    "threads are suffcient. \n",
    "\n",
    "#### Memory considerations\n",
    "\n",
    "Each thread has exclusive access to one location in the array and shared read access\n",
    "to another. Reads by multiple threads to the same location can be satisfied through\n",
    "caching and braoadcast.\n",
    "\n",
    "#### Synchronization\n",
    "\n",
    "Using the default stream, enqueue a sequence of thread launchs according to\n",
    "the having blocksize.\n",
    "\n",
    "#### Efficiency.\n",
    "\n",
    "This has log n phases, each phase using n/2 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6009c4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [ 3. 25.  1. 24. 10. 27. 30. 29.  0. 19.  8. 27.  3. 11.  2. 27. 29. 12.\n",
      " 18. 10. 22. 26. 10. 22.  0.  4. 30. 31.  3. 31. 10.  1.]\n",
      "a: [  3.  28.  29.  53.  63.  90. 120. 149. 149. 168. 176. 203. 206. 217.\n",
      " 219. 246. 275. 287. 305. 315. 337. 363. 373. 395. 395. 399. 429. 460.\n",
      " 463. 494. 504. 505.]\n",
      "error: 0.0\n"
     ]
    }
   ],
   "source": [
    "def test_partial_sum(k):\n",
    "    \n",
    "    # GPU KERNEL\n",
    "    \n",
    "    def raise_block(ctx,args):\n",
    "        (_m,_k,_tid), (a,k) =  ctx, args\n",
    "        a = _m[a]\n",
    "\n",
    "        t = _tid>>k\n",
    "        if (t%2)==1: \n",
    "            j = (t<<k)-1\n",
    "            a[_tid] += a[j]           \n",
    "\n",
    "    # test functionality\n",
    "    \n",
    "    def partial_sum_cpu(b):\n",
    "        for i in range(1,len(b)):\n",
    "            b[i] += b[i-1]\n",
    "            \n",
    "    def dist(a,b):\n",
    "        p = 0\n",
    "        for i in range(len(a)):\n",
    "            p = abs(a[i]-b[i])\n",
    "        return p\n",
    "            \n",
    "    # GPU simulation\n",
    "    \n",
    "    gpu = GPU()\n",
    "    gpu.addKernel('raise_block',raise_block)\n",
    "    \n",
    "    n = 2**k\n",
    "    a = (np.random.randint(0,n,n)).astype(float)\n",
    "    gpu.addMemory('a',a)\n",
    "    \n",
    "    b = a.copy()\n",
    "    partial_sum_cpu(b)\n",
    "    print(f'a: {a}')\n",
    "\n",
    "    for phase in range(k):\n",
    "        gpu.launch('raise_block',n,('a',phase))\n",
    "         \n",
    "    print(f'a: {a}')\n",
    "    print(f'error: {dist(a,b)}')\n",
    "    \n",
    "    \n",
    "test_partial_sum(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e027b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e870f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2d3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
